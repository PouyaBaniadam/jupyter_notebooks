{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ff69e3f15b036aa6",
      "metadata": {},
      "source": [
        "# Introduction to Clustering\n",
        "\n",
        "The field of Machine Learning is broadly categorized into **_4_** main approaches, as illustrated below.\n",
        "\n",
        "---\n",
        "\n",
        "$\n",
        "\\text{ü§ñ Machine Learning}\n",
        "\\begin{cases}\n",
        "  \\text{üßë‚Äçüè´ Supervised Learning} \\\\\n",
        "  \\text{üß© Unsupervised Learning} \\\\\n",
        "  \\text{‚öñÔ∏è Semi-supervised Learning} \\\\\n",
        "  \\text{üïπÔ∏è Reinforcement Learning}\n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "---\n",
        "\n",
        "This report will focus on **Clustering**, one of the primary tasks within the **'Unsupervised Learning'**.\n",
        "\n",
        "In many machine learning tasks, particularly in **'Supervised Learning'**, the primary goal is a prediction. An algorithm is trained on labeled data to predict an output, such as assigning a label to new, unseen data.\n",
        "\n",
        "From the other hand, **'Clustering'** is not designed to predict a specific output. Instead, its objective is to discover structures within the data by organizing it into meaningful groups, or \"clusters.\"\n",
        "\n",
        "---\n",
        "\n",
        "# A real world example\n",
        "\n",
        "## Bank Example: Finding Risky Customers\n",
        "\n",
        "Banks use clustering to figure out which customers are financially similar and what risk they pose.\n",
        "\n",
        "*   **Goal:** Group customers to manage financial risk.\n",
        "*   **Input:** The bank uses unlabeled financial data like a customers income, debt, and payment history, age and ....\n",
        "*   **Clustering Action:** The algorithm automatically sorts all customers into distinct groups, such as a **\"Low-Risk\"** cluster and a **\"High-Risk\"** cluster.\n",
        "*   **Impact:** The bank can then use these groups to make decisions. For example, they can offer their best interest rates and products to the Low-Risk group while restricting loans or services to the High-Risk group.\n",
        "\n",
        "---\n",
        "\n",
        "## Where to use clustering\n",
        "\n",
        "*   **Exploring data analysis**\n",
        "*   **Summary generation**\n",
        "*   **Outlier detection**\n",
        "*   **Finding duplicates**\n",
        "*   **Pre-processing data**\n",
        "\n",
        "---\n",
        "\n",
        "Now that you know the main idea about clustering, let's dive into the scientiffic parts.\n",
        "\n",
        "For all algorithms in clustering, we actually want to find similarities and dissimilarities.\n",
        "\n",
        "You might wonder why we need dissimilarities! Well the answer is straightforward. As you can see in the image below, we are trying to cluster similar items that are as close as possible together. From the other hand, we are trying to maximize the clusters distances from each other. Look at the image below to see it clearly:\n",
        "\n",
        "---\n",
        "\n",
        "![](assets/intra_inter.png)\n",
        "\n",
        "---\n",
        "\n",
        "As you can see, the yellow items are trying to stick together and stay close, but the green and bule ones are trying to get as far as possible! If we somehowe manage to maximize the **'intra-distances'** and also minimize **'inter-distances'**, we can claim that we are on the right track in clustering.\n",
        "\n",
        "So, the goals are:\n",
        "\n",
        "$$\\text{Dis} (x_1, x_2) \\downarrow$$\n",
        "*(Minimize the distance between points $\\mathbf{x_1}$ and $\\mathbf{x_2}$ in the same cluster)*\n",
        "\n",
        "$$\\text{Dis} (c_1, c_2) \\uparrow$$\n",
        "*(Maximize the distance between clusters $\\mathbf{c_1}$ and $\\mathbf{c_2}$)*\n",
        "\n",
        "---\n",
        "\n",
        "### What is distance and how to measure that?\n",
        "\n",
        "Well, there are many different ways to measure distances between 2 points in vector environment such as :\n",
        "\n",
        "*   **Euclidean**\n",
        "*   **Cosine**\n",
        "*   **Average distance**\n",
        "\n",
        "and ...\n",
        "\n",
        "For now, we are going to talk about '**Euclidean**'\n",
        "\n",
        "In mathematics, the Euclidean distance between two points in Euclidean space is the length of the line segment between them. It can be calculated from the Cartesian coordinates of the points using the Pythagorean theorem, and therefore is occasionally called the Pythagorean distance.\n",
        "\n",
        "You can see it clearly in the image below:\n",
        "\n",
        "---\n",
        "\n",
        "![](assets/euclidean_distance.jpg)\n",
        "\n",
        "---\n",
        "\n",
        "So, it's just simple math. We find the difference of different items like this.\n",
        "\n",
        "$$\n",
        "\\text{Dis}(x_i, x_j) = \\sqrt{\\sum_{k=1}^{n} (x_{ik} - x_{jk})^2}\n",
        "$$\n",
        "\n",
        "You might ask why we add some more steps like changing the numbers to its second power and then used a radical on all of it. Well, we always try to normalize our data with this method, so that we bring our data on the normal curve. It is always a good practice to do that.\n",
        "\n",
        "---\n",
        "\n",
        "### Example Distance Calculation (Euclidean)\n",
        "\n",
        "Imagine we have two data points (e.g., two customers) measured by two features: **Feature A** and **Feature B**.\n",
        "\n",
        "| Feature | Point $x_i$ | Point $x_j$ |\n",
        "| :---: | :---: | :---: |\n",
        "| **Feature A** | 2 | 5 |\n",
        "| **Feature B** | 8 | 4 |\n",
        "\n",
        "To calculate the Euclidean distance between $x_i$ and $x_j$, we follow the steps of the formula:\n",
        "\n",
        "**1. Calculate the difference and square it for each feature:**\n",
        "\n",
        "*   **Feature A:** $(2 - 5)^2 = (-3)^2 = 9$\n",
        "*   **Feature B:** $(8 - 4)^2 = (4)^2 = 16$\n",
        "\n",
        "**2. Sum the squared differences and take the square root:**\n",
        "\n",
        "The calculation for the distance is as follows:\n",
        "\n",
        "$$\n",
        "\\text{Dis}(x_i, x_j) = \\sqrt{(2-5)^2 + (8-4)^2}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Dis}(x_i, x_j) = \\sqrt{9 + 16} = \\sqrt{25} = 5\n",
        "$$\n",
        "\n",
        "The distance between the two points is **5**. This single number is what the clustering algorithm uses to determine how similar $x_i$ and $x_j$ are. A lower distance means higher similarity.\n",
        "\n",
        "---\n",
        "\n",
        "All right, now that we know the main concepts, lets' dive into our very first algorithm, called '**_K-means_**'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
     "display_name": "Python 3 (ipykernel)",
     "language": "python",
     "name": "python3"
    },
    "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
  "nbformat": 4,
  "nbformat_minor": 5
}